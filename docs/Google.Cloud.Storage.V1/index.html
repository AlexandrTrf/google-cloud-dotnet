<!DOCTYPE html>
<!--[if IE]><![endif]-->
<html>
  
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <title>Google.Cloud.Storage.V1 | Google.Cloud.Storage.V1 </title>
    <meta name="viewport" content="width=device-width">
    <meta name="title" content="Google.Cloud.Storage.V1 | Google.Cloud.Storage.V1 ">
    <meta name="generator" content="docfx 2.50.0.0">
    
    <link rel="shortcut icon" href="favicon.ico">
    <link rel="stylesheet" href="styles/docfx.vendor.css">
    <link rel="stylesheet" href="styles/docfx.css">
    <link rel="stylesheet" href="styles/main.css">
    <meta property="docfx:navrel" content="toc.html">
    <meta property="docfx:tocrel" content="toc.html">
    
    
    
  </head>
  <body data-spy="scroll" data-target="#affix" data-offset="120">
    <div id="wrapper">
      <header>
        
        <nav id="autocollapse" class="navbar navbar-inverse ng-scope" role="navigation">
          <div class="container">
            <div class="navbar-header">
              <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navbar">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
              </button>
              
              <a class="navbar-brand" href="index.html">
                <img id="logo" class="svg" src="logo.svg" alt="">
              </a>
            </div>
            <div class="collapse navbar-collapse" id="navbar">
              <form class="navbar-form navbar-right" role="search" id="search">
                <div class="form-group">
                  <input type="text" class="form-control" id="search-query" placeholder="Search" autocomplete="off">
                </div>
              </form>
            </div>
          </div>
        </nav>
        
        <div class="subnav navbar navbar-default">
          <div class="container hide-when-search" id="breadcrumb">
            <ul class="breadcrumb">
              <li></li>
            </ul>
          </div>
        </div>
      </header>
      <div role="main" class="container body-content hide-when-search">
        <div class="article row grid">
          <div class="col-md-10">
            <article class="content wrap" id="_content" data-uid="">
<h1 id="googlecloudstoragev1">Google.Cloud.Storage.V1</h1>

<p><code>Google.Cloud.Storage.V1</code> is a.NET client library for the <a href="https://cloud.google.com/storage/">Google Cloud Storage API</a>.
It wraps the <code>Google.Apis.Storage.v1</code> generated library, providing a higher-level API to make it easier to use.</p>
<p>Note:
This documentation is for version <code>3.4.0</code> of the library.
Some samples may not work with other versions.</p>
<h1 id="installation">Installation</h1>
<p>Install the <code>Google.Cloud.Storage.V1</code> package from NuGet. Add it to
your project in the normal way (for example by right-clicking on the
project in Visual Studio and choosing &quot;Manage NuGet Packages...&quot;).</p>
<h1 id="authentication">Authentication</h1>
<p>When running on Google Cloud Platform, no action needs to be taken to authenticate.</p>
<p>Otherwise, the simplest way of authenticating your API calls is to
download a service account JSON file then set the <code>GOOGLE_APPLICATION_CREDENTIALS</code> environment variable to refer to it.
The credentials will automatically be used to authenticate. See the <a href="https://cloud.google.com/docs/authentication/getting-started">Getting Started With
Authentication</a> guide for more details.</p>
<h1 id="getting-started">Getting started</h1>
<p>Common operations are exposed via the
<a href="api/Google.Cloud.Storage.V1.StorageClient.html">StorageClient</a> class.</p>
<h1 id="client-life-cycle-management">Client life-cycle management</h1>
<p>In many cases you don&#39;t need to worry about disposing of
<code>StorageClient</code> objects, and can create them reasonably freely -
but be aware that this <em>can</em> causes issues with memory and network
connection usage. We advise you to reuse a single client object if possible.
<code>StorageClient</code> is thread-safe, so in most cases a single object is
the simplest option.</p>
<p>If your architecture requires you to frequently create new client
objects, please dispose of them to help with timely resource
clean-up. See <a href="https://googleapis.github.io/google-cloud-dotnet/docs/guides/cleanup.html#rest-based-apis">the resource clean-up
guide</a>
for more details.</p>
<h1 id="sample-code">Sample code</h1>
<pre><code class="lang-cs">var client = StorageClient.Create();

// Create a bucket with a globally unique name
var bucketName = Guid.NewGuid().ToString();
var bucket = client.CreateBucket(projectId, bucketName);

// Upload some files
var content = Encoding.UTF8.GetBytes(&quot;hello, world&quot;);
var obj1 = client.UploadObject(bucketName, &quot;file1.txt&quot;, &quot;text/plain&quot;, new MemoryStream(content));
var obj2 = client.UploadObject(bucketName, &quot;folder1/file2.txt&quot;, &quot;text/plain&quot;, new MemoryStream(content));

// List objects
foreach (var obj in client.ListObjects(bucketName, &quot;&quot;))
{
    Console.WriteLine(obj.Name);
}

// Download file
using (var stream = File.OpenWrite(&quot;file1.txt&quot;))
{
    client.DownloadObject(bucketName, &quot;file1.txt&quot;, stream);
}
</code></pre><h2 id="signed-urls">Signed URLs</h2>
<p>Signed URLs can be created to provide limited access to specific buckets and
objects to anyone in possession of the URL, regardless of whether they have
a Google account.</p>
<p>For example, Signed URLs can be created to provide read-only access to
existing objects:</p>
<pre><code class="lang-cs">// Create a signed URL which can be used to get a specific object for one hour.
UrlSigner urlSigner = UrlSigner.FromServiceAccountCredential(credential);
string url = urlSigner.Sign(bucketName, objectName, TimeSpan.FromHours(1));

// Get the content at the created URL.
HttpResponseMessage response = await httpClient.GetAsync(url);
string content = await response.Content.ReadAsStringAsync();
</code></pre><p>Or write-only access to put specific object content into a bucket:</p>
<pre><code class="lang-cs">// Create a request template that will be used to create the signed URL.
var destination = &quot;places/world.txt&quot;;
UrlSigner.RequestTemplate requestTemplate = UrlSigner.RequestTemplate
    .FromBucket(bucketName)
    .WithObjectName(destination)
    .WithHttpMethod(HttpMethod.Put)
    .WithContentHeaders(new Dictionary&lt;string, IEnumerable&lt;string&gt;&gt; 
    {
        { &quot;Content-Type&quot;, new[] { &quot;text/plain&quot; } }
    });
// Create options specifying for how long the signer URL will be valid.
UrlSigner.Options options = UrlSigner.Options.FromDuration(TimeSpan.FromHours(1));
// Create a signed URL which allows the requester to PUT data with the text/plain content-type.
UrlSigner urlSigner = UrlSigner.FromServiceAccountCredential(credential);
string url = urlSigner.Sign(requestTemplate, options);

// Upload the content into the bucket using the signed URL.
string source = &quot;world.txt&quot;;

ByteArrayContent content;
using (FileStream stream = File.OpenRead(source))
{
    byte[] data = new byte[stream.Length];
    stream.Read(data, 0, data.Length);
    content = new ByteArrayContent(data)
    {
        Headers = { ContentType = new MediaTypeHeaderValue(&quot;text/plain&quot;) }
    };
}

HttpResponseMessage response = await httpClient.PutAsync(url, content);
</code></pre><h3 id="signing-urls-without-a-service-account-credential-file">Signing URLs without a service account credential file</h3>
<p>If you need to sign URLs but don&#39;t have a full service account
credential file (with private keys) available, you can create a
<code>UrlSigner.IBlobSigner</code> implementation to perform the signing part.
The most common implementation of this is likely to be to use the
IAM service to perform the signing, with the
<a href="https://www.nuget.org/packages/Google.Apis.Iam.v1/">Google.Apis.Iam.v1</a>
package. Here&#39;s a sample implementation:</p>
<pre><code class="lang-cs">internal sealed class IamServiceBlobSigner : UrlSigner.IBlobSigner
{
    private readonly IamService _iamService;
    public string Id { get; }

    internal IamServiceBlobSigner(IamService service, string id)
    {
        _iamService = service;
        Id = id;
    }

    public string CreateSignature(byte[] data) =&gt;
        CreateRequest(data).Execute().Signature;

    public async Task&lt;string&gt; CreateSignatureAsync(byte[] data, CancellationToken cancellationToken)
    {
        ProjectsResource.ServiceAccountsResource.SignBlobRequest request = CreateRequest(data);
        SignBlobResponse response = await request.ExecuteAsync(cancellationToken).ConfigureAwait(false);
        return response.Signature;
    }

    private ProjectsResource.ServiceAccountsResource.SignBlobRequest CreateRequest(byte[] data)
    {
        SignBlobRequest body = new SignBlobRequest { BytesToSign = Convert.ToBase64String(data) };
        string account = $&quot;projects/-/serviceAccounts/{Id}&quot;;
        ProjectsResource.ServiceAccountsResource.SignBlobRequest request =
            _iamService.Projects.ServiceAccounts.SignBlob(body, account);
        return request;
    }
}
</code></pre><p>(We may make this available in its own package at some point in the
future.)</p>
<p>To make use of this, the account making the request needs the
<code>iam.serviceAccounts.signBlob</code> permission, which is usually granted
via the &quot;Service Account Token Creator&quot; role.</p>
<p>Here&#39;s an example showing how you could use this to sign a
URL on behalf of the default Compute Engine credential on an
instance. (This example will only work when running on Google Cloud
Platform, as it relies on information from the metadata server.) If
you want to use a different service account, you could include the
account ID as part of your application configuration.</p>
<pre><code class="lang-cs">// First obtain the email address of the default service account for this instance from the metadata server.
HttpRequestMessage serviceAccountRequest = new HttpRequestMessage
{
    // Note: you could use 169.254.169.254 as the address to avoid a DNS lookup.
    RequestUri = new Uri(&quot;http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/email&quot;),
    Headers = { { &quot;Metadata-Flavor&quot;, &quot;Google&quot; } }
};
HttpResponseMessage serviceAccountResponse = await httpClient.SendAsync(serviceAccountRequest).ConfigureAwait(false);
serviceAccountResponse.EnsureSuccessStatusCode();
string serviceAccountId = await serviceAccountResponse.Content.ReadAsStringAsync();

// Create an IAM service client object using the default application credentials.
GoogleCredential iamCredential = await GoogleCredential.GetApplicationDefaultAsync();
iamCredential = iamCredential.CreateScoped(IamService.Scope.CloudPlatform);
IamService iamService = new IamService(new BaseClientService.Initializer
{
    HttpClientInitializer = iamCredential
});

// Create a request template that will be used to create the signed URL.
UrlSigner.RequestTemplate requestTemplate = UrlSigner.RequestTemplate
    .FromBucket(bucketName)
    .WithObjectName(objectName)
    .WithHttpMethod(HttpMethod.Get);
// Create options specifying for how long the signer URL will be valid.
UrlSigner.Options options = UrlSigner.Options.FromDuration(TimeSpan.FromHours(1));

// Create a URL signer that will use the IAM service for signing. This signer is thread-safe,
// and would typically occur as a dependency, e.g. in an ASP.NET Core controller, where the
// same instance can be reused for each request.
IamServiceBlobSigner blobSigner = new IamServiceBlobSigner(iamService, serviceAccountId);
UrlSigner urlSigner = UrlSigner.FromBlobSigner(blobSigner);

// Use the URL signer to sign a request for the test object for the next hour.
string url = await urlSigner.SignAsync(requestTemplate, options);

// Prove we can fetch the content of the test object with a simple unauthenticated GET request.
HttpResponseMessage response = await httpClient.GetAsync(url);
string content = await response.Content.ReadAsStringAsync();
</code></pre><h3 id="specifying-the-signing-version">Specifying the signing version</h3>
<p>(V4 signing is currently beta functionality.)</p>
<p>Google Cloud Storage supports two signing process versions: V2 and V4.
Currently the default is V2, although in the future the library may
be updated to use V4 by default.</p>
<p>To specify the URL signing versioning, use the
<a href="api/Google.Cloud.Storage.V1.UrlSigner.html#Google_Cloud_Storage_V1_UrlSigner_WithSigningVersion_Google_Cloud_Storage_V1_SigningVersion_">UrlSigner.WithSigningVersion</a>
method, specifying the signing version you wish to use. This does
not change the UrlSigner it is called on; it returns a new UrlSigner
that uses the specified version.</p>
<p>Note that V4 signing is restricted to generating URLs that are valid
for at most 7 days.</p>
<pre><code class="lang-cs">// Create a signed URL which can be used to get a specific object for one hour,
// using the V4 signing process.
UrlSigner urlSigner = UrlSigner
    .FromServiceAccountCredential(credential);
string url = urlSigner.Sign(bucketName, objectName, TimeSpan.FromHours(1), signingVersion: SigningVersion.V4);

// Get the content at the created URL.
HttpResponseMessage response = await httpClient.GetAsync(url);
string content = await response.Content.ReadAsStringAsync();
</code></pre><h2 id="uploading-objects-by-using-html-forms">Uploading objects by using HTML forms</h2>
<p>In some cases, you might need to allow your users to upload objects via HTML forms.
You can create signed POST policies that specify what is and is not allowed in such
scenarios.
You can read the <a href="https://cloud.google.com/storage/docs/authentication/signatures#policy-document">Policy Document</a>
documentation to get more information on how a POST policy document should be built.
You can read the <a href="https://cloud.google.com/storage/docs/xml-api/post-object">POST object</a>
documentation to get more details on how the forms should be built.</p>
<p>Below you will find some samples on how to create a signed POST policy.</p>
<p>Simplest approach, where you restrict the upload to a specific bucket and a 
specific object name.</p>
<pre><code class="lang-cs">// Create a signed post policy which can be used to upload a specific object and
// expires in 1 hour after creation.
UrlSigner urlSigner = UrlSigner
    .FromServiceAccountCredential(credential);
UrlSigner.Options options = UrlSigner.Options
    .FromDuration(TimeSpan.FromHours(1))
    .WithSigningVersion(SigningVersion.V4)
    .WithScheme(&quot;https&quot;);
UrlSigner.PostPolicy postPolicy = UrlSigner.PostPolicy.ForBucketAndKey(bucketName, objectName);
postPolicy.SetCustomField(UrlSigner.PostPolicyCustomElement.GoogleMetadata, &quot;x-goog-meta-test&quot;, &quot;data&quot;);

UrlSigner.SignedPostPolicy signedPostPolicy = await urlSigner.SignAsync(postPolicy, options);

// Create an HTML form including all the fields in the signed post policy.
StringBuilder form = new StringBuilder();
form.AppendLine($&quot;&lt;form action=\&quot;{signedPostPolicy.PostUrl}\&quot; method=\&quot;post\&quot; enctype=\&quot;multipart/form-data\&quot;&gt;&quot;);
foreach (var field in signedPostPolicy.Fields)
{
    form.AppendLine($&quot;&lt;input type=\&quot;hidden\&quot; name=\&quot;{field.Key}\&quot; value=\&quot;{field.Value}\&quot;&gt;&quot;);
}
// Include the file element. It should always be the last element in the form.
form.AppendLine(&quot;&lt;input name=\&quot;file\&quot; type=\&quot;file\&quot;&gt;&quot;);
form.AppendLine(&quot;&lt;input type=\&quot;submit\&quot; value=\&quot;Upload\&quot;&gt;&quot;);
form.AppendLine(&quot;&lt;/form&gt;&quot;);

// You can now save the form to file and serve it as static content
// or send it as the response to a request made to your application.
File.WriteAllText(&quot;PostPolicySimple.html&quot;, form.ToString());
</code></pre><p>Enforce how browser&#39;s cache will treat the uploaded object.</p>
<pre><code class="lang-cs">// Create a signed post policy which can be used to upload a specific object with a
// specific cache-control value and expires in 1 hour after creation.
UrlSigner urlSigner = UrlSigner
    .FromServiceAccountCredential(credential);
UrlSigner.Options options = UrlSigner.Options
    .FromDuration(TimeSpan.FromHours(1))
    .WithSigningVersion(SigningVersion.V4)
    .WithScheme(&quot;https&quot;);
UrlSigner.PostPolicy postPolicy = UrlSigner.PostPolicy.ForBucketAndKey(bucketName, objectName);
postPolicy.SetField(UrlSigner.PostPolicyStandardElement.Acl, &quot;public-read&quot;);
postPolicy.SetField(UrlSigner.PostPolicyStandardElement.CacheControl, &quot;public,max-age=86400&quot;);

UrlSigner.SignedPostPolicy signedPostPolicy = await urlSigner.SignAsync(postPolicy, options);

// Create an HTML form including all the fields in the signed post policy.
StringBuilder form = new StringBuilder();
form.AppendLine($&quot;&lt;form action=\&quot;{signedPostPolicy.PostUrl}\&quot; method=\&quot;post\&quot; enctype=\&quot;multipart/form-data\&quot;&gt;&quot;);
foreach (var field in signedPostPolicy.Fields)
{
    form.AppendLine($&quot;&lt;input type=\&quot;hidden\&quot; name=\&quot;{field.Key}\&quot; value=\&quot;{field.Value}\&quot;&gt;&quot;);
}
// Include the file element. It should always be the last element in the form.
form.AppendLine(&quot;&lt;input name=\&quot;file\&quot; type=\&quot;file\&quot;&gt;&quot;);
form.AppendLine(&quot;&lt;input type=\&quot;submit\&quot; value=\&quot;Upload\&quot;&gt;&quot;);
form.AppendLine(&quot;&lt;/form&gt;&quot;);

// You can now save the form to file and serve it as static content
// or send it as the response to a request made to your application.
File.WriteAllText(&quot;PostPolicyCacheControl.html&quot;, form.ToString());
</code></pre><p>You can also set starts-with conditions for some form elements. This means that the
posting form should contain that element with a value that matches the condition.</p>
<pre><code class="lang-cs">// Create a signed post policy which can be used to upload a specific object and
// expires in 10 seconds after creation.
// It also sets a starts-with condition on the acl form element, that should be met
// by the actual form used for posting.
UrlSigner urlSigner = UrlSigner
    .FromServiceAccountCredential(credential);
UrlSigner.Options options = UrlSigner.Options
    .FromDuration(TimeSpan.FromHours(1))
    .WithSigningVersion(SigningVersion.V4)
    .WithScheme(&quot;https&quot;);
UrlSigner.PostPolicy postPolicy = UrlSigner.PostPolicy.ForBucketAndKey(bucketName, objectName);
postPolicy.SetStartsWith(UrlSigner.PostPolicyStandardElement.Acl, &quot;public&quot;);

UrlSigner.SignedPostPolicy signedPostPolicy = await urlSigner.SignAsync(postPolicy, options);

// Create an HTML form including all the fields in the signed post policy.
StringBuilder form = new StringBuilder();
form.AppendLine($&quot;&lt;form action=\&quot;{signedPostPolicy.PostUrl}\&quot; method=\&quot;post\&quot; enctype=\&quot;multipart/form-data\&quot;&gt;&quot;);
foreach (var field in signedPostPolicy.Fields)
{
    form.AppendLine($&quot;&lt;input type=\&quot;hidden\&quot; name=\&quot;{field.Key}\&quot; value=\&quot;{field.Value}\&quot;&gt;&quot;);
}
// Include also an acl element with a value that meets the condition set in the policy.
form.AppendLine(&quot;&lt;input type=\&quot;hidden\&quot; name=\&quot;acl\&quot; value=\&quot;public-read\&quot;&gt;&quot;);
// Include the file element. It should always be the last element in the form.
form.AppendLine(&quot;&lt;input name=\&quot;file\&quot; type=\&quot;file\&quot;&gt;&quot;);
form.AppendLine(&quot;&lt;input type=\&quot;submit\&quot; value=\&quot;Upload\&quot;&gt;&quot;);
form.AppendLine(&quot;&lt;/form&gt;&quot;);

// You can now save the form to file and serve it as static content
// or send it as the response to a request made to your application.
File.WriteAllText(&quot;PostPolicyAcl.html&quot;, form.ToString());
</code></pre><p>Tell the server which HTTP status code you want it to return on succes.</p>
<pre><code class="lang-cs">// Create a signed post policy which can be used to upload a specific object and
// expires in 1 hour after creation.
// It also sets a specific HTTP success satus code that should be returned.
// Only 200, 201 and 204 are allowed.
UrlSigner urlSigner = UrlSigner
    .FromServiceAccountCredential(credential);
UrlSigner.Options options = UrlSigner.Options
    .FromDuration(TimeSpan.FromHours(1))
    .WithSigningVersion(SigningVersion.V4)
    .WithScheme(&quot;https&quot;);
UrlSigner.PostPolicy postPolicy = UrlSigner.PostPolicy.ForBucketAndKey(bucketName, objectName);
postPolicy.SetField(UrlSigner.PostPolicyStandardElement.SuccessActionStatus, HttpStatusCode.OK);

UrlSigner.SignedPostPolicy signedPostPolicy = await urlSigner.SignAsync(postPolicy, options);

// Create an HTML form including all the fields in the signed post policy.
StringBuilder form = new StringBuilder();
form.AppendLine($&quot;&lt;form action=\&quot;{signedPostPolicy.PostUrl}\&quot; method=\&quot;post\&quot; enctype=\&quot;multipart/form-data\&quot;&gt;&quot;);
foreach (var field in signedPostPolicy.Fields)
{
    form.AppendLine($&quot;&lt;input type=\&quot;hidden\&quot; name=\&quot;{field.Key}\&quot; value=\&quot;{field.Value}\&quot;&gt;&quot;);
}
// Include the file element. It should always be the last element in the form.
form.AppendLine(&quot;&lt;input name=\&quot;file\&quot; type=\&quot;file\&quot;&gt;&quot;);
form.AppendLine(&quot;&lt;input type=\&quot;submit\&quot; value=\&quot;Upload\&quot;&gt;&quot;);
form.AppendLine(&quot;&lt;/form&gt;&quot;);

// You can now save the form to file and serve it as static content
// or send it as the response to a request made to your application.
File.WriteAllText(&quot;PostPolicySuccessStatus.html&quot;, form.ToString());
</code></pre><h2 id="upload-uris">Upload URIs</h2>
<p>In some cases, it may not make sense for client applications to have permissions
to begin an upload for an object, but an authenticated service may choose to grant
this ability for individual uploads. Signed URLs are one option for this. Another
option is for the service to start a resumable upload session, but instead of
performing the upload, sending the resulting upload URI to the client application
so it can perform the upload instead. Unlike sessions initiated with a signed URL,
a pre-initated upload session will force the client application to upload through
the region in which the session began, which will likely be close to the service,
and not necessarily the client.</p>
<pre><code class="lang-cs">var client = StorageClient.Create();
var source = &quot;world.txt&quot;;
var destination = &quot;places/world.txt&quot;;
var contentType = &quot;text/plain&quot;;

// var acl = PredefinedAcl.PublicRead // public
var acl = PredefinedObjectAcl.AuthenticatedRead; // private
var options = new UploadObjectOptions { PredefinedAcl = acl };
// Create a temporary uploader so the upload session can be manually initiated without actually uploading.
var tempUploader = client.CreateObjectUploader(bucketName, destination, contentType, new MemoryStream(), options);
var uploadUri = await tempUploader.InitiateSessionAsync();

// Send uploadUri to (unauthenticated) client application, so it can perform the upload:
using (var stream = File.OpenRead(source))
{
    // IUploadProgress defined in Google.Apis.Upload namespace
    IProgress&lt;IUploadProgress&gt; progress = new Progress&lt;IUploadProgress&gt;(
      p =&gt; Console.WriteLine($&quot;bytes: {p.BytesSent}, status: {p.Status}&quot;)
    );

    var actualUploader = ResumableUpload.CreateFromUploadUri(uploadUri, stream);
    actualUploader.ProgressChanged += progress.Report;
    await actualUploader.UploadAsync();
}
</code></pre><h2 id="customer-supplied-encryption-keys">Customer-supplied encryption keys</h2>
<p>Storage objects are always stored encrypted, but if you wish to
specify your own encryption key instead of using the server-supplied
one, you can do so either for all operations with a particular
<code>StorageClient</code> or on individual ones.</p>
<pre><code class="lang-cs">// Use EncryptionKey.Create if you already have a key.
EncryptionKey key = EncryptionKey.Generate();

// This will affect all relevant object-based operations by default.
var client = StorageClient.Create(encryptionKey: key);
var content = Encoding.UTF8.GetBytes(&quot;hello, world&quot;);
client.UploadObject(bucketName, &quot;encrypted.txt&quot;, &quot;text/plain&quot;, new MemoryStream(content));

// When downloading, either use a client with the same key...
client.DownloadObject(bucketName, &quot;encrypted.txt&quot;, new MemoryStream());

// Or specify a key just for that operation.
var client2 = StorageClient.Create();
client2.DownloadObject(bucketName, &quot;encrypted.txt&quot;, new MemoryStream(),
    new DownloadObjectOptions { EncryptionKey = key });
</code></pre><h2 id="change-notification-via-google-cloud-pubsub">Change notification via Google Cloud Pub/Sub</h2>
<p>You can configure a bucket to send a change notification to a
<a href="https://cloud.google.com/pubsub/">Google Cloud Pub/Sub</a> topic
when changes occur. The sample below shows how to create a Pub/Sub
topic, set its permissions so that the change notifications can be
published to it, and then create the notification configuration on a
bucket. You&#39;ll need to add a dependency on the
<code>Google.Cloud.PubSub.V1</code> NuGet package to create the topic and
manage its permissions.</p>
<pre><code class="lang-cs">// First create a Pub/Sub topic.
PublisherServiceApiClient publisherClient = PublisherServiceApiClient.Create();
TopicName topicName = new TopicName(projectId, topicId);
publisherClient.CreateTopic(topicName);

// Prepare the topic for Storage notifications. The Storage Service Account must have Publish permission
// for the topic. The code below adds the service account into the &quot;roles/pubsub.publisher&quot; role for the topic.

// Determine the Storage Service Account name to use in IAM operations.
StorageClient storageClient = StorageClient.Create();
string storageServiceAccount = $&quot;serviceAccount:{storageClient.GetStorageServiceAccountEmail(projectId)}&quot;;

// Fetch the IAM policy for the topic.
Iam.V1.Policy policy = publisherClient.GetIamPolicy(topicName.ToString());
var role = &quot;roles/pubsub.publisher&quot;;

// Ensure the Storage Service Account is in the publisher role, setting the IAM policy for the topic
// on the server if necessary.
if (policy.AddRoleMember(role, storageServiceAccount))
{
    publisherClient.SetIamPolicy(topicName.ToString(), policy);
}

// Now that the topic is ready, we can create a notification configuration for Storage
Notification notification = new Notification
{
    Topic = $&quot;//pubsub.googleapis.com/{topicName}&quot;,
    PayloadFormat = &quot;JSON_API_V1&quot;
};
notification = storageClient.CreateNotification(bucket, notification);
Console.WriteLine($&quot;Created notification ID: {notification.Id}&quot;);

</code></pre></article>
          </div>
          
          <div class="hidden-sm col-md-2" role="complementary">
            <div class="sideaffix">
              <nav class="bs-docs-sidebar hidden-print hidden-xs hidden-sm affix" id="affix">
              <!-- <p><a class="back-to-top" href="#top">Back to top</a><p> -->
              </nav>
            </div>
          </div>
        </div>
      </div>
      
      <footer>
        <div class="grad-bottom"></div>
        <div class="footer">
          <div class="container">
            <span class="pull-right">
              <a href="#top">Back to top</a>
            </span>
             
            
          </div>
        </div>
      </footer>
    </div>
    
    <script type="text/javascript" src="styles/docfx.vendor.js"></script>
    <script type="text/javascript" src="styles/docfx.js"></script>
    <script type="text/javascript" src="styles/main.js"></script>
  </body>
</html>
